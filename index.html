<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Multiple object detection using pre trained model in TensorFlow.js</title>
    <meta charset="utf-8">
    <!-- Import the webpage's stylesheet -->
    <link rel="stylesheet" href="style.css">
    <style>
    body {
  font-family: helvetica, arial, sans-serif;
  margin: 2em;
  color: #3D3D3D;
}

#instruction{
  background-color:lightblue;
  box-shadow: 10px 10px lightgrey;
  padding:10px;
  font-weight:bold;
  
}



h1 {
  font-style: italic;
  color: #FF6F00;
}

video {
  display: inline-block;
}

section {
  opacity: 1;
  transition: opacity 500ms ease-in-out;
}

.removed {
  display: none;
}

.invisible {
  opacity: 0.2;
}

.camView {
  position: relative;
  float: left;
  width: calc(100% - 20px);
  margin: 10px;
  cursor: pointer;
}

.camView p {
  position: absolute;
  padding: 5px;
  background-color: rgba(255, 111, 0, 0.85);
  color: #FFF;
  border: 1px dashed rgba(255, 255, 255, 0.7);
  z-index: 2;
  font-size: 12px;
}

.highlighter {
  background: rgba(0, 255, 0, 0.25);
  border: 1px dashed #fff;
  z-index: 1;
  position: absolute;
}
    </style>
  </head>  
  <body>
    <h1>Exam Cheating detection</h1>
    <div id="instruction">
  
    <h1>Instruction and features:</h1>
    <ul>
        <li><p>if user use any type of object like phones or book to cheat the webcam detect object send data to faculty router </p> </li>
         <li> <p>at real time faculty catch the user objects<p></li>
       <li><p>if user stop the webcame it alert a sound and also the data send to router</p></li>
    <li><p>if user resize the screen it alert a sound</p></li>
    <li><p>if user mov to the new tab it alert a sound as well as data are send to router</p></li>
   
    </ul>   
   
    </div>

    
    <section id="demos" class="invisible">

      
      
      <div id="liveView" class="camView">
        <button id="webcamButton">Enable Webcam</button>
        <button id="stop">Stop</button>
        <video id="webcam" autoplay muted width="640" height="480"></video>
      </div>
    </section>

    
    <!-- Import TensorFlow.js library -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js" type="text/javascript"></script>
    <!-- Load the coco-ssd model to use to recognize things in images -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    
    <!-- Import the page's JavaScript to do some stuff -->
  <script src="index.js" defer></script>

<script>
var stopsound = document.getElementById("stop");
stopsound.addEventListener("click",()=>{
  
 var music = new Audio('al.mp3');
   music.play();
 //  alert("DONT STOP THE CAMERA** ");
 console.lof("stopping camera")

});





document.addEventListener("visibilitychange", (event) => {
  if (document.visibilityState == "visible") {
    console.log("tab is active")
  } else {

    var music = new Audio('al.mp3');
   music.play();
         alert("DONT MOVE TO NEXT TAB** ");
     
      console.log("tab is inactive")
  }
});

window.onresize = function(event) {

  var music = new Audio('al.mp3');
   music.play();
    
   alert("DONT MOVE TO MINIMIZE A TAB** ");
   console.log("resizing window");
};




















//basic code
const video = document.getElementById('webcam');
const liveView = document.getElementById('liveView');
const demosSection = document.getElementById('demos');
const enableWebcamButton = document.getElementById('webcamButton');


// Check if webcam access is supported.
function getUserMediaSupported() {
    return !!(navigator.mediaDevices &&
      navigator.mediaDevices.getUserMedia);
  }
  
  // If webcam supported, add event listener to button for when user
  // wants to activate it to call enableCam function which we will 
  // define in the next step.
  if (getUserMediaSupported()) {
    enableWebcamButton.addEventListener('click', enableCam);
  } else {
    console.warn('getUserMedia() is not supported by your browser');
  }

  function enableCam(event) {
    // Only continue if the COCO-SSD has finished loading.
    if (!model) {
      return;
    }
    
    // Hide the button once clicked.
    event.target.classList.add('removed');  
    
    // getUsermedia parameters to force video but not audio.
    const constraints = {
      video: true
    };
  
    // Activate the webcam stream.
    navigator.mediaDevices.getUserMedia(constraints).then(function(stream) {
      video.srcObject = stream;
      video.addEventListener('loadeddata', predictWebcam);
    });
  }
  // Placeholder function for next step.
function predictWebcam() {
}

// Pretend model has loaded so we can try out the webcam code.
var model = true;
demosSection.classList.remove('invisible');
// Store the resulting model in the global scope of our app.
var model = undefined;

// Before we can use COCO-SSD class we must wait for it to finish
// loading. Machine Learning models can be large and take a moment 
// to get everything needed to run.
// Note: cocoSsd is an external object loaded from our index.html
// script tag import so ignore any warning in Glitch.
cocoSsd.load().then(function (loadedModel) {
  model = loadedModel;
  // Show demo section now model is ready to use.
  demosSection.classList.remove('invisible');
});

var children = [];

function predictWebcam() {
  // Now let's start classifying a frame in the stream.
  model.detect(video).then(function (predictions) {
    // Remove any highlighting we did previous frame.
    for (let i = 0; i < children.length; i++) {
      liveView.removeChild(children[i]);
    }
    children.splice(0);
    
    // Now lets loop through predictions and draw them to the live view if
    // they have a high confidence score.
    for (let n = 0; n < predictions.length; n++) {
      // If we are over 66% sure we are sure we classified it right, draw it!
      if (predictions[n].score > 0.66) {
        const p = document.createElement('p');
        p.innerText = predictions[n].class  + ' - with ' 
            + Math.round(parseFloat(predictions[n].score) * 100) 
            + '% confidence.';
        p.style = 'margin-left: ' + predictions[n].bbox[0] + 'px; margin-top: '
            + (predictions[n].bbox[1] - 10) + 'px; width: ' 
            + (predictions[n].bbox[2] - 10) + 'px; top: 0; left: 0;';

        const highlighter = document.createElement('div');
        highlighter.setAttribute('class', 'highlighter');
        highlighter.style = 'left: ' + predictions[n].bbox[0] + 'px; top: '
            + predictions[n].bbox[1] + 'px; width: ' 
            + predictions[n].bbox[2] + 'px; height: '
            + predictions[n].bbox[3] + 'px;';

        liveView.appendChild(highlighter);
        liveView.appendChild(p);
        children.push(highlighter);
        children.push(p);

        //my change
     const foo = predictions[0];

     
console.log(foo);




     
      }
    }
    
    // Call this function again to keep predicting when the browser is ready.
    window.requestAnimationFrame(predictWebcam);
  });

 function sendConsoleMessage(type, message) {
  const xhr = new XMLHttpRequest();
  xhr.open('POST', '/log');
  xhr.setRequestHeader('Content-Type', 'application/json');
  xhr.send(JSON.stringify({ type, message }));
}

// redirect console.log to send messages to the server
console.log = (message) => {
  sendConsoleMessage('log', message);
 //tryyyyyyyy
if(message === "person"){
  alert("j")
}
};

// redirect console.error to send error messages to the server
console.error = (message) => {
  sendConsoleMessage('error', message);

};
/// try the model
function getConsoleOutput() {
  const xhr = new XMLHttpRequest();
  xhr.open('GET', '/console');
  xhr.onreadystatechange = () => {
    if (xhr.readyState === XMLHttpRequest.DONE && xhr.status === 200) {
      const output = JSON.parse(xhr.responseText);
      console.log(output);
    }

  };
  xhr.send();

 
}






















  //lat bracket
}
</script>



  </body>
</html>